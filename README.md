# Titanic Survival Prediction

In this project I built a model to compete in Kaggle's competition to predict who survived the Titanic disaster and who did not. Feature engineering, model selection and model tuning are the key elements of the work. Models used are logistic regression, K nearest neighbor and random forest (for classification).

This project was a 'guided project' as part of learning data science with [Dataquest](https://www.dataquest.io).

## Results

To display the result, simply [click the .ipynb file](https://github.com/jasperquak/titanic_survival_prediction/blob/main/TitanicSurvivalPrediction.ipynb) in this repository. It will open in a Notebook viewer.

## Reproduction

In case you want to reproduce the project in a Jupyter Notebook in your own environment.

Download both the .ipynb file and the files functions.py train.csv, test.csv into the same folder.

Before starting Jupyter Notebook, ensure that you have the following packages installed:
* pandas
* numpy
* datetime
* matplotlib.pyplot

* sklearn.ensemble
* sklearn.neighbors
* sklearn.linear_model
* sklearn.feature_selection
* sklearn.model_selection

## About the data source

The data that is used in this project was downloaded from [Kaggle's Titanic disaster competition page](https://www.kaggle.com/competitions/titanic/data)
